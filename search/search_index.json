{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to DynaCLI Documentation : DynaCLI Github Pages Source Code : py-dynacli DynaCLI (Dynamic CLI) is a cloud-friendly Python library for converting pure Python functions into Linux Shell commands on the fly. Unlike other existing solutions such as Click and Typer , there is no need for any function decorators. Further, unlike with all existing solutions, including those built on top of standard argparse , DynaCLI does not build all command parsers upfront, but rather builds dynamically a single command parser based on the command line inputs. When combined with the Python Cloud Importer solution DynaCLI becomes truly open with regard to a practically unlimited set of commands, all coming directly from cloud storage. This, in turn, eliminates any need for periodic updates on client workstations. At its score, DynaCLI is a Python package structure interpreter which makes any public function executable from the command line. DynaCLI was developed by BST LABS as an open source generic infrastructure foundation for the cloud version of Python run-time within the scope of the Cloud AI Operating System (CAIOS) project. DynaCLI is based on Python 3.9+, standard Python docstrings and Python type hints. DynaCLI key differentiators are: Fast : DynaCLI builds argparse parser hierarchy only for one command thus eliminating the need for preparing parsers for all available commands. Open : adding new command or group of commands (called feature) is as easy as dropping implementation module(s) in right place of import tree. Frameworkless : no need to import anything in command modules. Just write plain Python functions with built-in type arguments (*argv and **kwargs are supported as well). Zero dependencies : only one module built on top of standard Python library to install. No heavy dependencies dragged in. Robust : potential defect in any command will not take down the whole system.","title":"DynaCLI"},{"location":"#welcome-to-dynacli","text":"Documentation : DynaCLI Github Pages Source Code : py-dynacli DynaCLI (Dynamic CLI) is a cloud-friendly Python library for converting pure Python functions into Linux Shell commands on the fly. Unlike other existing solutions such as Click and Typer , there is no need for any function decorators. Further, unlike with all existing solutions, including those built on top of standard argparse , DynaCLI does not build all command parsers upfront, but rather builds dynamically a single command parser based on the command line inputs. When combined with the Python Cloud Importer solution DynaCLI becomes truly open with regard to a practically unlimited set of commands, all coming directly from cloud storage. This, in turn, eliminates any need for periodic updates on client workstations. At its score, DynaCLI is a Python package structure interpreter which makes any public function executable from the command line. DynaCLI was developed by BST LABS as an open source generic infrastructure foundation for the cloud version of Python run-time within the scope of the Cloud AI Operating System (CAIOS) project. DynaCLI is based on Python 3.9+, standard Python docstrings and Python type hints. DynaCLI key differentiators are: Fast : DynaCLI builds argparse parser hierarchy only for one command thus eliminating the need for preparing parsers for all available commands. Open : adding new command or group of commands (called feature) is as easy as dropping implementation module(s) in right place of import tree. Frameworkless : no need to import anything in command modules. Just write plain Python functions with built-in type arguments (*argv and **kwargs are supported as well). Zero dependencies : only one module built on top of standard Python library to install. No heavy dependencies dragged in. Robust : potential defect in any command will not take down the whole system.","title":"Welcome to DynaCLI"},{"location":"types/","text":"Python types If you need a refresher about how to use Python type hints, read here Python Type Checking (Guide) . You can also check the mypy cheat sheet . In short (very short), you can declare a function with parameters like: from enum import Enum class Color ( Enum ): WHITE = 1 RED = 2 def type_example ( name : str , formal : bool , exit : int , amount : float , color : Color , * args : str , ** kwargs : int ): pass And your editor (and DynaCLI ) will know that: name is type of str and is a required parameter. formal is type of bool and is a required parameter. exit is type of int and is a required parameter. amount is type of float and is a required parameter. color is type of Color and is a required parameter. *args variable length arguments with type of str . **kwargs keyword arguments with type of int . These type hints are what give you autocomplete in your editor and several other features. DynaCLI is based on these type hints.","title":"Python Types Intro"},{"location":"types/#python-types","text":"If you need a refresher about how to use Python type hints, read here Python Type Checking (Guide) . You can also check the mypy cheat sheet . In short (very short), you can declare a function with parameters like: from enum import Enum class Color ( Enum ): WHITE = 1 RED = 2 def type_example ( name : str , formal : bool , exit : int , amount : float , color : Color , * args : str , ** kwargs : int ): pass And your editor (and DynaCLI ) will know that: name is type of str and is a required parameter. formal is type of bool and is a required parameter. exit is type of int and is a required parameter. amount is type of float and is a required parameter. color is type of Color and is a required parameter. *args variable length arguments with type of str . **kwargs keyword arguments with type of int . These type hints are what give you autocomplete in your editor and several other features. DynaCLI is based on these type hints.","title":"Python types"},{"location":"advanced/docstrings/","text":"Supported Docstring format You can read about available docstring formats in this article: Docstring Formats We opt for Google style which is described here: PyGuide Functions and Methods You can use the following docstring as a reference: test.py def test ( name : str , age : int , is_student : bool , * args : str , ** kwargs : int ) -> None : \"\"\" The test function... Args: name (str): name of the applicant age (int): age of the applicant is_student (bool): if the applicant is student or not *args (str): some variable length arguments **kwargs (int): keyword arguments Return: None \"\"\"","title":"Docstring formats"},{"location":"advanced/docstrings/#supported-docstring-format","text":"You can read about available docstring formats in this article: Docstring Formats We opt for Google style which is described here: PyGuide Functions and Methods You can use the following docstring as a reference: test.py def test ( name : str , age : int , is_student : bool , * args : str , ** kwargs : int ) -> None : \"\"\" The test function... Args: name (str): name of the applicant age (int): age of the applicant is_student (bool): if the applicant is student or not *args (str): some variable length arguments **kwargs (int): keyword arguments Return: None \"\"\"","title":"Supported Docstring format"},{"location":"advanced/how_dynacli_works/","text":"How DynaCLI Works DynaCLI library is a simple preprocessor for the argparse standard Python library. It scans the sys.argv array to process command line arguments one by one, uses the importlib.import_module function to bring in feature packages/modules and command modules, uses the inspect.signature to understand command function arguments and the re.match function to extract help string per argument. If it encounters a StopIteration or ModuleNotFound exception, it will use the pkgutil.iter_modules function to build help for available features and commands. The overall structure of DynaCLI library is illustrated below:","title":"How DynaCLI Works"},{"location":"advanced/how_dynacli_works/#how-dynacli-works","text":"DynaCLI library is a simple preprocessor for the argparse standard Python library. It scans the sys.argv array to process command line arguments one by one, uses the importlib.import_module function to bring in feature packages/modules and command modules, uses the inspect.signature to understand command function arguments and the re.match function to extract help string per argument. If it encounters a StopIteration or ModuleNotFound exception, it will use the pkgutil.iter_modules function to build help for available features and commands. The overall structure of DynaCLI library is illustrated below:","title":"How DynaCLI Works"},{"location":"advanced/search-path/","text":"DynaCLI search path and root packages DynaCLI is supposed to be easy to use in easy cases and at the same time extremely flexible and cloud friendly. The last concept deserves some extra explanations. The DynaCLI was conceived to address special needs of the Cloud AI Operating System (CAIOS) project, which employs a special custom Python Cloud Importer as the major underlying technology. Briefly, the main idea behind the CAIOS Python Cloud Importer is that developers do not need to pip install anything, but just to import what_your_need from the cloud storage. Here, we could envision at least three types of cloud storage where importable artifacts could be located: the main system cloud storage shared by everybody (System Storage on the diagram below) cloud storage of a particular system installation shared by a group of developers (Group Storage on the diagram below) individual developer's storage (User Storage on the diagram below) Therefore, when a developer types import something this something could be imported from her personal User Storage, Group Storage shared with developers from her group, and System Storage shared with all developers. In fact, this is just a most the most typical system configuration. By itself DynaCLI does not limit how many which types of storage should be in the system as long as they all are supported by the underlying Python Import System. Regardless of how many storages there are, each such storage should be reflected in the DynaCLI search_path list. On the other hand, in general case, not all commands should be available to any user. Some commands are intended for developers but could be occasionally used by administrators. Some other commands should be available only for administrators of particular system installations (Group Administrator on the diagram below), while some other commands should be available for the system administrators. We, therefore need some form of command access control, be it Role-Base Access Control (RBAC) or even Attribute-Based Access Control (ABAC) . DynaCLI addresses this need by assuming that each set of commands intended for particular group of users (developers, administrators, etc.) is located under a particular Python Root Package and allows to configure them as a separate list in DynalCLI entry point. Notice that DynaCLI entry point does not have to be static. It could be dynamically generated at, say, system installation. Combing these two mechanisms, we come up with a many-to-many types of configurations, namely, that each type of storage might contain different root packages with commands intended for different types of users. This virtually unlimited flexibility in system configuration, is what makes DynaCLI so different from any other Python CLI framework. Assuming AWS as a cloud platform (it will work equally well for any cloud, we just want to be specific), the diagram below illustrates a typical system configuration of 3 types of storage (System, Group, User) and two types of users (Developer, Administrator) accesses from two AWS cloud accounts: Notice, that DynaCLI search path and root package configuration is not limited to cloud storage only (in this example AWS S3). Some artifacts could still be imported from a local disk for boostrap or access time optimization purposes. There is virtually no limit in what could be achieved here. TODO: Shako to check if anything from below should be retained For DynaCLI search path has special meaning - it can use local packages or modules or those are stored in the cloud. There is no difference either it is getting imported from S3 or from the local machine. Also, you can divide the functionality of your CLI - there can be situations where we need to provide some features for administrative users , and some features to the developers. So, basically you can provide different search paths, and it will be reflected accordingly: Here we have 2 different CLIs testcli and testcliadmin . Accordingly, testcliadmin will see all features for the dev ( testcli ), because it is an admin: For Developers: $ ./testcli -h usage: testcli [-h] [-v] {destroy,feature-A,service,update,fake,feature-B,the-last,upload} ... Sample DynaCLI Tool positional arguments: {destroy,feature-A,service,update,fake,feature-B,the-last,upload} destroy Destroy given name... feature-A Does something useful service This is an example of module feature update Updates everything... fake [ERROR] Missing the module docstring feature-B Does something extremely useful the-last This is an example of module feature upload This is an example of module feature optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit Administrators: $ ./testcliadmin -h usage: testcliadmin [-h] [-v] {destroy,feature-A,service,update,feature-C,fake,feature-B,the-last,upload,feature-D} ... Sample DynaCLI Tool positional arguments: {destroy,feature-A,service,update,feature-C,fake,feature-B,the-last,upload,feature-D} destroy Destroy given name... feature-A Does something useful service This is an example of module feature update Updates everything... feature-C For admin users fake [ERROR] Missing the module docstring feature-B Does something extremely useful the-last This is an example of module feature upload This is an example of module feature feature-D Do not forget about this feature for admins optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit As you have noticed new 2 features were registered ( feature-C , feature-D ), they can be either from cloud or from the local.","title":"Search Path manipulation"},{"location":"advanced/search-path/#dynacli-search-path-and-root-packages","text":"DynaCLI is supposed to be easy to use in easy cases and at the same time extremely flexible and cloud friendly. The last concept deserves some extra explanations. The DynaCLI was conceived to address special needs of the Cloud AI Operating System (CAIOS) project, which employs a special custom Python Cloud Importer as the major underlying technology. Briefly, the main idea behind the CAIOS Python Cloud Importer is that developers do not need to pip install anything, but just to import what_your_need from the cloud storage. Here, we could envision at least three types of cloud storage where importable artifacts could be located: the main system cloud storage shared by everybody (System Storage on the diagram below) cloud storage of a particular system installation shared by a group of developers (Group Storage on the diagram below) individual developer's storage (User Storage on the diagram below) Therefore, when a developer types import something this something could be imported from her personal User Storage, Group Storage shared with developers from her group, and System Storage shared with all developers. In fact, this is just a most the most typical system configuration. By itself DynaCLI does not limit how many which types of storage should be in the system as long as they all are supported by the underlying Python Import System. Regardless of how many storages there are, each such storage should be reflected in the DynaCLI search_path list. On the other hand, in general case, not all commands should be available to any user. Some commands are intended for developers but could be occasionally used by administrators. Some other commands should be available only for administrators of particular system installations (Group Administrator on the diagram below), while some other commands should be available for the system administrators. We, therefore need some form of command access control, be it Role-Base Access Control (RBAC) or even Attribute-Based Access Control (ABAC) . DynaCLI addresses this need by assuming that each set of commands intended for particular group of users (developers, administrators, etc.) is located under a particular Python Root Package and allows to configure them as a separate list in DynalCLI entry point. Notice that DynaCLI entry point does not have to be static. It could be dynamically generated at, say, system installation. Combing these two mechanisms, we come up with a many-to-many types of configurations, namely, that each type of storage might contain different root packages with commands intended for different types of users. This virtually unlimited flexibility in system configuration, is what makes DynaCLI so different from any other Python CLI framework. Assuming AWS as a cloud platform (it will work equally well for any cloud, we just want to be specific), the diagram below illustrates a typical system configuration of 3 types of storage (System, Group, User) and two types of users (Developer, Administrator) accesses from two AWS cloud accounts: Notice, that DynaCLI search path and root package configuration is not limited to cloud storage only (in this example AWS S3). Some artifacts could still be imported from a local disk for boostrap or access time optimization purposes. There is virtually no limit in what could be achieved here. TODO: Shako to check if anything from below should be retained For DynaCLI search path has special meaning - it can use local packages or modules or those are stored in the cloud. There is no difference either it is getting imported from S3 or from the local machine. Also, you can divide the functionality of your CLI - there can be situations where we need to provide some features for administrative users , and some features to the developers. So, basically you can provide different search paths, and it will be reflected accordingly: Here we have 2 different CLIs testcli and testcliadmin . Accordingly, testcliadmin will see all features for the dev ( testcli ), because it is an admin: For Developers: $ ./testcli -h usage: testcli [-h] [-v] {destroy,feature-A,service,update,fake,feature-B,the-last,upload} ... Sample DynaCLI Tool positional arguments: {destroy,feature-A,service,update,fake,feature-B,the-last,upload} destroy Destroy given name... feature-A Does something useful service This is an example of module feature update Updates everything... fake [ERROR] Missing the module docstring feature-B Does something extremely useful the-last This is an example of module feature upload This is an example of module feature optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit Administrators: $ ./testcliadmin -h usage: testcliadmin [-h] [-v] {destroy,feature-A,service,update,feature-C,fake,feature-B,the-last,upload,feature-D} ... Sample DynaCLI Tool positional arguments: {destroy,feature-A,service,update,feature-C,fake,feature-B,the-last,upload,feature-D} destroy Destroy given name... feature-A Does something useful service This is an example of module feature update Updates everything... feature-C For admin users fake [ERROR] Missing the module docstring feature-B Does something extremely useful the-last This is an example of module feature upload This is an example of module feature feature-D Do not forget about this feature for admins optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit As you have noticed new 2 features were registered ( feature-C , feature-D ), they can be either from cloud or from the local.","title":"DynaCLI search path and root packages"},{"location":"advanced/state-machine/","text":"DynalCLI State Machine Internally, DynaCLI main routine is implemented by applying the State Design Pattern (more specifically, function_for_state , but these are internal details) using a state machine for keeping track of the command line arguments processing progress. At high-level, this state machine, illustrated using the lightweight UML Statecharts notation, is presented below: We treat every command line argument as a trigger trying to figure out what to do about it: the first entry of sys.argv is treated as a DynaCLI entry point, from which we extract high-level description and version info, if any (_initial_state on the diagram) every next argument is treated as a Python module name, imported using the importlib.import_module function (_waiting_for_feature_or_command state on the diagram) if import fails, or there are more entries in sys.arg, help for all available features (at the current level) is generated using the pkgutil.iter_modules function if import succeeds, the imported module is analysed whether it has an __all__ specifier or not (we follow Python convention with regard to __all__ specification) if it does have __all__ , then based on whether it's a Python package or module, the processing transits to either _waiting_for_package_feature_all or _waiting_for_module_feature_all state (see bellow more detailed description) otherwise, if imported module is a package, we extract the package help and version info, if any, using the __init__.py file docstring and __version__ specification and push the argparse parsers hierarchy one level down if it's a regular module, we check if it has a function with the same name if it does have a function with the same name, we treat it as a command module, build complete command parser by analysing the function signature and docstring, and transit to the final processing if it does not have a function with the same module, we treat it as a feature module (each public function will be treated as a command) and transit to _waiting_for_feature_module_command_state in the _waiting_for_package_feature_all state, we check whether the next sys.argv entry is in the __all__ list; if it is we perform a normal state selection process outlined above, if it is not, we print a help for this feature package in the _waiting_for_module_feature_all state, we check whether the next sys.argv entry is in the __all__ list; if it is we treat it as a command, if it is not, we print a help for this feature module in the _waiting_for_feature_module_command, we check whether the next sys.argv entry points to a public function within this module; if it does we treat it as a command, if it does not, we print a help for this feature module at the final stage, we invoke the argparse standard parsing mechanism, check whether a pointer to command function was obtained and either execute this command if it was, or print usage message ( argparse will print an error message if something was wrong) Why argparse at all? One could argue that DynaCLI actually uses the argparse for printing help and usage messages while actual processing is done by the DynaCLI internal machinery. If so, the question would be \"why to use the argparse at all\". First, this observation is correct. Second, we wanted to retain the argparse message formatting, which is considered as de-facto standard. Third, considering limited resources and specific needs of the main CAIOS project, we did not want to invest in excavating help and usage message formatting from the argparse internals. While it might add some minor performance overhead we considered it negligible and worth our development effort savings. TODO: Shako to check whether anything from below still needs to be retained Each state corresponds to a different level. Effectively, we have 3 main states: feature as a package handler, feature as a module handler and command handler. But there is a different state called __all__ handler for going through a different path if there is a __all__ indicated at feature as a package level and feature as a module level. There is no need to indicate __all__ at top level command because it makes no sense. Basically, we treat each CLI sequence of the commands as different states: $ ./testcli <feature> <command> -h States in this CLI run is described below: At each iteration we find ourselves in specific state, yes we use State Design Pattern: First iteration -> testcli - the script itself is an initial state. Second iteration -> <feature> - feature as package or feature as module state. Third iteration -> <command> - command state. Fourth iteration -> Iterator is exhausted and raised StopIteration that means we are going to build command help. Let's describe some more variations: Variations: ./testcli -h : initial state - StopIteration - build all features help ./testcli <feature as package> -h : initial state - add feature as parser - StopIteration - build feature help ./testcli <feature as module> -h : initial state - add feature as parser - StopIteration - build feature as module help ./tescli <feature> <command> -h : initial state - add feature parser - add command parser - StopIteration - build command help ./tescli <feature> <command> arg1 arg2 \u2026 : initial state - add feature parser - add command parser - register arguments - execute the function And based on the fact that if __all__ was found we got different path to follow but the main idea is to have states for each path. Note To explore pUML please click and open the photo in large size","title":"State Machine"},{"location":"advanced/state-machine/#dynalcli-state-machine","text":"Internally, DynaCLI main routine is implemented by applying the State Design Pattern (more specifically, function_for_state , but these are internal details) using a state machine for keeping track of the command line arguments processing progress. At high-level, this state machine, illustrated using the lightweight UML Statecharts notation, is presented below: We treat every command line argument as a trigger trying to figure out what to do about it: the first entry of sys.argv is treated as a DynaCLI entry point, from which we extract high-level description and version info, if any (_initial_state on the diagram) every next argument is treated as a Python module name, imported using the importlib.import_module function (_waiting_for_feature_or_command state on the diagram) if import fails, or there are more entries in sys.arg, help for all available features (at the current level) is generated using the pkgutil.iter_modules function if import succeeds, the imported module is analysed whether it has an __all__ specifier or not (we follow Python convention with regard to __all__ specification) if it does have __all__ , then based on whether it's a Python package or module, the processing transits to either _waiting_for_package_feature_all or _waiting_for_module_feature_all state (see bellow more detailed description) otherwise, if imported module is a package, we extract the package help and version info, if any, using the __init__.py file docstring and __version__ specification and push the argparse parsers hierarchy one level down if it's a regular module, we check if it has a function with the same name if it does have a function with the same name, we treat it as a command module, build complete command parser by analysing the function signature and docstring, and transit to the final processing if it does not have a function with the same module, we treat it as a feature module (each public function will be treated as a command) and transit to _waiting_for_feature_module_command_state in the _waiting_for_package_feature_all state, we check whether the next sys.argv entry is in the __all__ list; if it is we perform a normal state selection process outlined above, if it is not, we print a help for this feature package in the _waiting_for_module_feature_all state, we check whether the next sys.argv entry is in the __all__ list; if it is we treat it as a command, if it is not, we print a help for this feature module in the _waiting_for_feature_module_command, we check whether the next sys.argv entry points to a public function within this module; if it does we treat it as a command, if it does not, we print a help for this feature module at the final stage, we invoke the argparse standard parsing mechanism, check whether a pointer to command function was obtained and either execute this command if it was, or print usage message ( argparse will print an error message if something was wrong)","title":"DynalCLI State Machine"},{"location":"advanced/types/","text":"Supported Python Types Currently, we support following Python types as argument types in functions: Supported: int , float , str , bool , Enum Unsupported: Optional[] , Union[] , list , tuple , dict etc. Even without unsupported type hints(and actual types) of arguments, you can easily replace them with *args and **kwargs , which are supported.","title":"Supported types"},{"location":"advanced/types/#supported-python-types","text":"Currently, we support following Python types as argument types in functions: Supported: int , float , str , bool , Enum Unsupported: Optional[] , Union[] , list , tuple , dict etc. Even without unsupported type hints(and actual types) of arguments, you can easily replace them with *args and **kwargs , which are supported.","title":"Supported Python Types"},{"location":"advanced/why/","text":"DynaCLI vs. Alternatives There are so many libraries out there for writing command line utilities; why choose DynaCLI? Let's take a brief look at some common Python CLI libraries: Python argparse Google python-fire Tiangolo Typer Pallet's Click We'll review them one by one trying to understand the benefits and limitations of each: Python argparse DynaCLI is built on top of argparse but the latter by itself is insufficient: it requires the manual construction of every parser. While this approach provides maximum flexibility, it's also tedious and error-prone. Also, typical usage of argparse assumes building all parsers and sub-parsers upfront. The irony is that each CLI invocation will execute only one command, so all other CPU cycles are wasted. When the number of commands is large, it starts to be a serious problem exacerbated by the fact that, in the case of Cloud AI Operating System (CAIOS) , all command function modules come from cloud storage. Having said all this, argparse establishes an industry-wide standard of how CLI help and usage messages should look like, and DynaCLI uses it internally as explained in more details here . Google python-fire This library shares with DynaCLI the main approach of converting ordinary Python functions into Bash commands. It even goes further, supporting class methods. DynaCLI does not support classes at the moment, but we may consider supporting them in the future (there is nothing spectacularly complex about classes). Google python-fire provides some additional attractive features such as function call chaining, interactivity, and shell completion. Like DynaCLI, Google python-fire is built on top of Python argparse and uses its internal machinery for configuring parsers and help and usage messages. Google python-fire also supports custom serialization, keyword arguments (with -- prefix), direct access to object properties and local variables. Google python-fire does not rely on type annotations but rather converts command line arguments to the most suitable types automatically on the fly. However, unlike DynaCLI, Google python-fire is not open with regard to the potential number of commands and command groups (we call them features). Specifically, the main module should import fire (similar to from dynacli import main ), but it also assumes either defining in place or importing ALL functions and classes one wants to convert into Bash commands. DynaCLI does not do this; instead it relies on the search path and root packages configurations, based on which any number of Python functions will be converted into commands automatically. While DynaCLI does not support classes at the moment (we simply did not see enough need for them), it does support unlimited nesting of command groups (feature packages) as well as correct interpretation of __all__ specification and packge __init__.py imports. As the result, the Google python-fire library is relatively large: i.e., 10s of Python modules. In comparison, DynaCLI comprises one Python module with less than 700 lines, including blanks and docstrings. Library size and number of features mean complexity and stability, and we were looking for something as small as possible... we seldom, if at all, will need to update. The main difference between DynaCLI and Google python-fire is that it was built with a distinct strategic goal in mind: to provide a minimal footprint for a completely extensible set of administrative commands coming from vendors and customers alike. Many extra features of Google python-fire that are missing in DynaCLI could be added as dynamic plugins, if we decide to support them. Custom serialization would be a good example. We deliberately decided not to support them at this time, arguing that it would increase compelxity without too much benefit: custom conversions of string arguments could be easily implemented at the command function level without the introduction of a parallel plugin structure. Following similar logic, we decided not to support named and optional arguments. We preferred treating command functions as belonging to the service layer , restricted to bult-in type arguments with basic support for variable-length parameters via *args and **kwargs . Anything else could be implemented on top of that basic machinery without introducing added complexity and inflating the library's footprint. We will continue learning about Google python-fire and keeping track of its evolution. We will probably incorporate most useful of its features into DynaCLI. Tiangolo Typer Conceptually, Tiangolo Typer usage is similar to that of Google python-fire - it converts plain Python functions into commands. Unlike Google python-fire and similar to DynaCLI, it does rely on argument types annotation. Unlike both of them, it is not implemented directly on top of Python argparse , but rather on top of Pallet's Click , which of course, inflates the overal library footprint, which we were trying to avoid in DynaCLI. Like DynaCLI, it generates automatically commands help from function docstrings and type annotations. Feature-wise, Tiangolo Typer is very close to Google python-fire , but it leverages type annotations whenever possible. That in turn, allows effective integration with IDEs. It also uses colorama for controlling output colors. For that purpose, Tiangolo Typer recommends using its special echo() function. In DynaCLI, we decided not to pursue this direction at the moment, permitting every command function to print or log whatever it needs. As with many other command line tools, we want to be able to develop service functions equally utilisable via CLI and REST API interfaces. For that reason, using Python Logging infrastructure is very often preferable. We also considered automatic printing (or logging) of function return values to be included in a future version. As with many other features, we want to avoid increasing the library footprint through features most of daily operations could easily be performed without. Interestingly enough, Tiangolo Typer documentation mentions two other CLI Python frameworks: Hug and Plac . They both are based on Python function decorators and conceptually are similar to Pallet's Click . The main limitation of Tiangolo Typer is the same as with Google python-fire - ALL command functions have to be brought in (aka imported) upfront, which violates the basic DynaCLI premise to be a completely open and cloud-friendly library with a minimal installed footprint. By no means we were willing to trade these properties for more features and flexibility; more often than not these enhancements are not that critical or worth the extra complexity. Pallet's Click This is probably the most widely used and powerful Python CLI library. It does not seem to be implemented on top of argparse , but rather on top of optparse - the argparse predecessor, which was deprecated since Python version 3.2 and has not been further developed. It has a relatively large footprint by itself (this needs to be taken into consideration for Tiangolo Typer ). The main feature of Pallet's Click , which makes it so powerful and flexible, was an absolute no-go for us - it is based on Python function decorators . DynaCLI from the very outset was intended for converting into Bash commands regular Python functions that, at least in principle, could be reused in other contexts, such as REST API Services. Summary All the libraries mentioned above do not properly address the main DynaCLI requirements: complete openes - all command functions are brought in via dynamic imports from, presumably, cloud storage. no function decorators - command functions could be, at least in principle, reused in other contexts. minimal footprint - the core library has to be as small and as stable as possible, built on top of standard Python library. All extra features, if any, should be introduced via dynamic imports. At the moment, the DynaCLI library satisfies all requirements of the sponsoring Cloud AI Operating System (CAIOS) project. Should additional needs or high-demand enhancements arise, such as command chaining or autocompletion, and these could be added without violating the main requirements outlined above, we will consider doing so in or accepting contributions to future versions of DynaCLI.","title":"Why DynaCLI?"},{"location":"advanced/why/#dynacli-vs-alternatives","text":"There are so many libraries out there for writing command line utilities; why choose DynaCLI? Let's take a brief look at some common Python CLI libraries: Python argparse Google python-fire Tiangolo Typer Pallet's Click We'll review them one by one trying to understand the benefits and limitations of each:","title":"DynaCLI vs. Alternatives"},{"location":"manual/","text":"Reference Manual This reference shows you how to use DynaCLI with most of its features, step by step. Each section gradually builds on the previous ones, but it's structured to separate topics, so that you can go directly to any specific one to solve your specific needs. It is also built to work as a future reference. So you can come back and see exactly what you need. Install DynaCLI $ pip3 install dynacli As we have zero 3rd party dependencies, DynaCLI will just install single module and that's it.","title":"DynaCLI installation"},{"location":"manual/#reference-manual","text":"This reference shows you how to use DynaCLI with most of its features, step by step. Each section gradually builds on the previous ones, but it's structured to separate topics, so that you can go directly to any specific one to solve your specific needs. It is also built to work as a future reference. So you can come back and see exactly what you need.","title":"Reference Manual"},{"location":"manual/cli-entrypoint/","text":"Building CLI We are going to build simple CLI app in this tutorial. We called it awesome . First let's define our project structure: $ mkdir awesome $ touch awesome/awesome Create the storages: $ mkdir -p storage_X/cli/dev $ mkdir -p storage_Y/cli/dev Now we will define our CLI entrypoint as: #!/usr/bin/env python3 import sys import os from dynacli import main cwd = os . path . dirname ( __file__ ) search_path = [ f ' { cwd } /storage_X/cli/dev' , f ' { cwd } /storage_Y/cli/dev' ] sys . path . extend ( search_path ) main ( search_path ) If you wonder what is this search_path , please refer to DynaCLI is cloud friendly section of Advanced Reference Manual. The next is to start adding package as features.","title":"CLI entrypoint"},{"location":"manual/cli-entrypoint/#building-cli","text":"We are going to build simple CLI app in this tutorial. We called it awesome . First let's define our project structure: $ mkdir awesome $ touch awesome/awesome Create the storages: $ mkdir -p storage_X/cli/dev $ mkdir -p storage_Y/cli/dev Now we will define our CLI entrypoint as: #!/usr/bin/env python3 import sys import os from dynacli import main cwd = os . path . dirname ( __file__ ) search_path = [ f ' { cwd } /storage_X/cli/dev' , f ' { cwd } /storage_Y/cli/dev' ] sys . path . extend ( search_path ) main ( search_path ) If you wonder what is this search_path , please refer to DynaCLI is cloud friendly section of Advanced Reference Manual. The next is to start adding package as features.","title":"Building CLI"},{"location":"manual/module-as-feature/","text":"Module as feature Module as feature is a standalone module which is not located in the package(I.E it is not a package as feature). It is a regular .py module file with functions in it - but it has no identical named function in it. Let's add module as feature called upload.py : $ touch storage_X/cli/dev/upload.py And add the docstring in the upload.py file: upload.py \"\"\" This is an example of module feature \"\"\" If you run the CLI: $ ./awesome -h usage: awesome [ -h ] { service,upload,environment } ... positional arguments: { service,upload,environment } service The service feature to handle our services # (1) upload This is an example of module feature # (2) environment The environment feature to handle our environments # (3) optional arguments: -h, --help show this help message and exit Package as feature from storage_X Module as feature from storage_X Package as feature from storage_Y Feature Commands With package as feature the commands are modules with identical named functions in it. In contrast, here we are going to add multiple functions in the upload.py - effectively multiple commands. upload.py \"\"\" This is an example of module feature \"\"\" def new ( name : str ) -> None : \"\"\" uploads a new file Args: name (str): Name of file Return: None \"\"\" print ( f \"This is a module as feature { name } \" ) def delete ( name : str , environment : str ) -> None : \"\"\" Deletes a file from given environment Args: name (str): Name of project environment (str): Name of the env Return: None \"\"\" print ( f \"Delete a module as feature { name } { environment } \" ) def _init (): \"\"\" This should not be shown Return: None \"\"\" ... def __revert (): \"\"\" This should not be shown Return: None \"\"\" ... In Python convention something starting with single or double underscore considered as \"protected\" or \"private\". We like this idea and those commands(functions) are silently ignored and are not considered as commands: $ ./awesome upload -h usage: awesome upload [-h] {new,delete} ... positional arguments: {new,delete} new uploads a new file delete Deletes a file from given environment optional arguments: -h, --help show this help message and exit Finally, let's run this new command: $ ./awesome upload new -h usage: awesome upload new [-h] name positional arguments: name Name of file optional arguments: -h, --help show this help message and exit $ ./awesome upload new file This is a module as feature file Versioning module as feature As with package as features you can add __version__ in the module as feature to indicate your unique version: upload.py \"\"\" This is an example of module feature \"\"\" __version__ = \"5.0\" def new ( name : str ) -> None : Now you can get the version as well: $ ./awesome upload new --version awesome upload new - v5.0 Limiting the feature commands If for some reason you have a \"public\" function in the module, and you do not want to expose it as a command you can limit it by using __all__ . Originally in Python __all__ only limits the imports such as: from something import *. But here we use it just for eliminating the redundant operations when we register the feature commands: upload.py \"\"\" This is an example of module feature \"\"\" __version__ = \"5.0\" __all__ = [ \"new\" ] def new ( name : str ) -> None : Now if you look at the help of the feature: $ ./awesome upload -h usage: awesome upload [-h] [-v] {new} ... positional arguments: {new} new uploads a new file optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit And if you try to bypass(because you are sure there is a delete function): $ ./awesome upload delete -h usage: awesome upload [-h] [-v] {new} ... awesome upload: error: invalid choice: 'delete' (choose from 'new') The next is to learn about top level commands.","title":"Module as feature"},{"location":"manual/module-as-feature/#module-as-feature","text":"Module as feature is a standalone module which is not located in the package(I.E it is not a package as feature). It is a regular .py module file with functions in it - but it has no identical named function in it. Let's add module as feature called upload.py : $ touch storage_X/cli/dev/upload.py And add the docstring in the upload.py file: upload.py \"\"\" This is an example of module feature \"\"\" If you run the CLI: $ ./awesome -h usage: awesome [ -h ] { service,upload,environment } ... positional arguments: { service,upload,environment } service The service feature to handle our services # (1) upload This is an example of module feature # (2) environment The environment feature to handle our environments # (3) optional arguments: -h, --help show this help message and exit Package as feature from storage_X Module as feature from storage_X Package as feature from storage_Y","title":"Module as feature"},{"location":"manual/package-as-feature/","text":"Package as feature Now it is time to add our package as features: $ mkdir storage_X/cli/dev/service $ touch storage_X/cli/dev/service/__init__.py $ mkdir storage_Y/cli/dev/environment $ touch storage_Y/cli/dev/environment/__init__.py That's it you can now run your CLI: $ ./awesome -h usage: awesome [-h] {service,environment} ... positional arguments: {service,environment} service [ERROR] Missing the module docstring environment [ERROR] Missing the module docstring optional arguments: -h, --help show this help message and exit Our packages have no docstrings in it, due to this fact we got an ERROR indicating that we are missing the docstrings. Let's quickly fix this. We are going to add docstrings to the __init__.py files. Open the storage_X / cli / dev / service / __init__ . py and add following: \"\"\"The service feature to handle our services\"\"\" Open the storage_Y / cli / dev / environment / __init__ . py and add following: \"\"\"The environment feature to handle our environments\"\"\" Now if you rerun the CLI you can see that there are no ERROR s: $ ./awesome -h usage: awesome [-h] {service,environment} ... positional arguments: {service,environment} service The service feature to handle our services environment The environment feature to handle our environments optional arguments: -h, --help show this help message and exit Feature commands What kind of operations we want for our service feature? Let's imagine that we can create, update and shutdown the services. That means we need new.py , update.py and shutdown.py files in service package: $ touch storage_X/cli/dev/service/new.py $ touch storage_X/cli/dev/service/update.py $ touch storage_X/cli/dev/service/shutdown.py We consider commands in the package as feature if they have identical named function in it. In other words, there should be new () function in new.py , update () in update.py etc. So, let's define our functions(feature commands): new.py def new ( name : str , path : str ): \"\"\" init the new project in given path Args: name (str): name of the project path (str): path where to create service Return: None \"\"\" print ( f \"Initializing the { name } in { path } \" ) update.py def update ( name : str , version : float , upgrade : bool , * args : str , ** kwargs : int ) -> None : \"\"\" Updates the service... Args: name (str): name of the service version (float): new version upgrade (bool): if to upgrade everything *args (str): variable length arguments **kwargs (int): keyword arguments Return: None \"\"\" print ( f \"Updating... { name } to { version } with { upgrade =} using { args } and { kwargs } \" ) shutdown.py def shutdown ( environment : str , service : str ) -> None : \"\"\" shutdown the service Args: environment (str): environment name (e.g. Cloud9 IDE stack) service (str): name of the service Return: None \"\"\" print ( f \"This is a shutdown of { service } from { environment } !\" ) Now let's get information about service feature: $ ./awesome service -h usage: awesome service [-h] {new,shutdown,update} ... positional arguments: {new,shutdown,update} new init the new project in given path shutdown shutdown the service update Updates the service... optional arguments: -h, --help show this help message and exit How about each command? $ ./awesome service update -h usage: awesome service update [-h] name version upgrade [args ...] [kwargs <name>=<value> ...] positional arguments: name name of the service version new version upgrade if to upgrade everything args variable length arguments kwargs <name>=<value> keyword arguments optional arguments: -h, --help show this help message and exit Now let's call the update command: $ ./awesome service update myservice 2 .0 True lib1 lib2 version1 = 1 .2 version2 = 1 .3 Updating... myservice to 2.0 with upgrade=True using ('lib1', 'lib2') and {'version1': 1.2, 'version2': 1.3} As you have already noticed we have converted the CLI commands to the function arguments with proper type conversion. Versioning your features and commands Now imagine the case, when for some reason you have a bunch of features with different versions and also your commands have different versioning. You can easily handle it, by adding __version__ in the feature and commands. Open the storage_X/cli/dev/service/__init__.py and add: \"\"\"The service feature to handle our services\"\"\" __version__ = \"1.0\" Now you can get the version of the feature: $ ./awesome service --version awesome service - v1.0 Same for update command: update.py __version__ = \"2.0\" def update ( name : str , version : float , upgrade : bool , * args : str , ** kwargs : float ) -> None : ... $ ./awesome service update --version awesome service update - v2.0 Limiting the feature commands You may have a situation, when you have other helper modules inside the feature package, and you do not want to expose them as a feature command. In that case you can leverage the __all__ mechanism. Originally in Python __all__ only limits the imports such as: from something import * . But here we use it just for eliminating the redundant operations when we register the feature commands. So let's eliminate shutdown command from our service feature without removing it. Update the __init__.py file of the service feature: \"\"\"The service feature to handle our services\"\"\" from . import * __version__ = \"1.0\" __all__ = [ \"new\" , \"update\" ] And now try to get the help, as you have already noticed shutdown command is not available: $ ./awesome service -h usage: awesome service [-h] [-v] {new,update} ... positional arguments: {new,update} new init the new project in given path update Updates the service... optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit If you try to bypass this guard(because you know that there is a shutdown.py file indeed): $ ./awesome service shutdown -h usage: awesome service [-h] [-v] {new,update} ... awesome service: error: invalid choice: 'shutdown' (choose from 'new', 'update') The next is to explore module as features.","title":"Package as feature"},{"location":"manual/package-as-feature/#package-as-feature","text":"Now it is time to add our package as features: $ mkdir storage_X/cli/dev/service $ touch storage_X/cli/dev/service/__init__.py $ mkdir storage_Y/cli/dev/environment $ touch storage_Y/cli/dev/environment/__init__.py That's it you can now run your CLI: $ ./awesome -h usage: awesome [-h] {service,environment} ... positional arguments: {service,environment} service [ERROR] Missing the module docstring environment [ERROR] Missing the module docstring optional arguments: -h, --help show this help message and exit Our packages have no docstrings in it, due to this fact we got an ERROR indicating that we are missing the docstrings. Let's quickly fix this. We are going to add docstrings to the __init__.py files. Open the storage_X / cli / dev / service / __init__ . py and add following: \"\"\"The service feature to handle our services\"\"\" Open the storage_Y / cli / dev / environment / __init__ . py and add following: \"\"\"The environment feature to handle our environments\"\"\" Now if you rerun the CLI you can see that there are no ERROR s: $ ./awesome -h usage: awesome [-h] {service,environment} ... positional arguments: {service,environment} service The service feature to handle our services environment The environment feature to handle our environments optional arguments: -h, --help show this help message and exit","title":"Package as feature"},{"location":"manual/top-level-command/","text":"Top Level Command Top level command is a module with identical named function in it. It is similar to package as a feature, except it is a module not package. I.E it is a module as feature with identical named function in it. Let's create sample one: $ touch storage_X/cli/dev/destroy.py Define the command as: destroy.py def destroy ( name : str ) -> None : \"\"\" Destroy given name...(top level command) Args: name (str): Name of project Return: None \"\"\" print ( f \"This is a top level destroyer - { name } \" ) Get the help message: $ ./awesome -h usage: awesome [ -h ] { destroy,service,upload,environment } ... positional arguments: { destroy,service,upload,environment } destroy Destroy given name... ( top level command ) # (1) service The service feature to handle our services # (2) upload This is an example of module feature # (3) environment The environment feature to handle our environments # (4) optional arguments: -h, --help show this help message and exit Top level command from storage_X Package as feature from storage_X Module as feature from storage_X Package as feature from storage_Y Get the top level command help: $ ./awesome destroy -h usage: awesome destroy [-h] name positional arguments: name Name of project optional arguments: -h, --help show this help message and exit Run the top level command: $ ./awesome destroy please This is a top level destroyer - please Versioning You can add a unique version to your top level command by adding __version__ : destroy.py __version__ = \"1.1a1\" def destroy ( name : str ) -> None : Get the version information: ./awesome destroy -h usage: awesome destroy [-h] [-v] name positional arguments: name Name of project optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit $ ./awesome destroy --version awesome destroy - v1.1a1","title":"Top level command"},{"location":"manual/top-level-command/#top-level-command","text":"Top level command is a module with identical named function in it. It is similar to package as a feature, except it is a module not package. I.E it is a module as feature with identical named function in it. Let's create sample one: $ touch storage_X/cli/dev/destroy.py Define the command as: destroy.py def destroy ( name : str ) -> None : \"\"\" Destroy given name...(top level command) Args: name (str): Name of project Return: None \"\"\" print ( f \"This is a top level destroyer - { name } \" ) Get the help message: $ ./awesome -h usage: awesome [ -h ] { destroy,service,upload,environment } ... positional arguments: { destroy,service,upload,environment } destroy Destroy given name... ( top level command ) # (1) service The service feature to handle our services # (2) upload This is an example of module feature # (3) environment The environment feature to handle our environments # (4) optional arguments: -h, --help show this help message and exit Top level command from storage_X Package as feature from storage_X Module as feature from storage_X Package as feature from storage_Y Get the top level command help: $ ./awesome destroy -h usage: awesome destroy [-h] name positional arguments: name Name of project optional arguments: -h, --help show this help message and exit Run the top level command: $ ./awesome destroy please This is a top level destroyer - please","title":"Top Level Command"},{"location":"todo-app/","text":"TODO app We use a To-Do app idea from Build a Command-Line To-Do App With Python and Typer Of course, we are going to change and omit unneeded sections. The goal is to show how DynaCLI can ease the process of building CLI apps. Create TODO directory and create todo file: $ tree . \u2514\u2500\u2500 TODO \u2514\u2500\u2500 todo 1 directory, 1 file CLI entrypoint is quite simple without any pre-configuration: todo #!/usr/bin/env python3 \"\"\" TODO CLI APP \"\"\" import sys import os from dynacli import main __version__ = \"1.0\" cwd = os . path . dirname ( __file__ ) sys . path . extend ([ cwd ]) main ([ cwd ]) And now we have nice help with description and also with the version. Basically, we get the CLI help from the docstring, version from __version__ and there is no need for any callback. $ ./todo -h usage: todo [-h] [-v] {} ... TODO CLI APP positional arguments: {} optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit $ ./todo --version todo - v1.0 The next is to init the Todo project.","title":"TODO - Intro"},{"location":"todo-app/#todo-app","text":"We use a To-Do app idea from Build a Command-Line To-Do App With Python and Typer Of course, we are going to change and omit unneeded sections. The goal is to show how DynaCLI can ease the process of building CLI apps. Create TODO directory and create todo file: $ tree . \u2514\u2500\u2500 TODO \u2514\u2500\u2500 todo 1 directory, 1 file CLI entrypoint is quite simple without any pre-configuration: todo #!/usr/bin/env python3 \"\"\" TODO CLI APP \"\"\" import sys import os from dynacli import main __version__ = \"1.0\" cwd = os . path . dirname ( __file__ ) sys . path . extend ([ cwd ]) main ([ cwd ]) And now we have nice help with description and also with the version. Basically, we get the CLI help from the docstring, version from __version__ and there is no need for any callback. $ ./todo -h usage: todo [-h] [-v] {} ... TODO CLI APP positional arguments: {} optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit $ ./todo --version todo - v1.0 The next is to init the Todo project.","title":"TODO app"},{"location":"todo-app/init/","text":"todo init command The simplest way of storing our todos is constructing a .json file with given name. At this point it is different from original post , and we consider it is simpler to store tasks as: (Status, Task name) style in .json file. We consider the database as a project name where the tasks should reside. If you want to create a task management for your daily routine - that means, we need to init the daily database(or daily project). This is called initialization, so we have created init.py file: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u2514\u2500\u2500 todo 1 directory, 2 files init.py import json def init ( project_name : str ) -> None : \"\"\" Initialize the .json file with given name Args: project_name (str): the name of the todo project Return: None \"\"\" data = { project_name : []} with open ( f \" { project_name } .json\" , \"w\" ) as f : json . dump ( data , f ) print ( \"Created: \" , project_name + \".json\" ) That is it now we have nice help message, and we can initialize our \"database\" json file: $ ./todo init -h usage: todo init [-h] project_name positional arguments: project_name the name of the todo project optional arguments: -h, --help show this help message and exit Run the init command: $ ./todo init daily Created: daily.json The final tree: $ tree -I __pycache__ . \u251c\u2500\u2500 init.py \u251c\u2500\u2500 daily.json \u2514\u2500\u2500 todo 0 directories, 3 files The next command is to implement todo remove command - I.E deleting .json file.","title":"Init the database"},{"location":"todo-app/init/#todo-init-command","text":"The simplest way of storing our todos is constructing a .json file with given name. At this point it is different from original post , and we consider it is simpler to store tasks as: (Status, Task name) style in .json file. We consider the database as a project name where the tasks should reside. If you want to create a task management for your daily routine - that means, we need to init the daily database(or daily project). This is called initialization, so we have created init.py file: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u2514\u2500\u2500 todo 1 directory, 2 files init.py import json def init ( project_name : str ) -> None : \"\"\" Initialize the .json file with given name Args: project_name (str): the name of the todo project Return: None \"\"\" data = { project_name : []} with open ( f \" { project_name } .json\" , \"w\" ) as f : json . dump ( data , f ) print ( \"Created: \" , project_name + \".json\" ) That is it now we have nice help message, and we can initialize our \"database\" json file: $ ./todo init -h usage: todo init [-h] project_name positional arguments: project_name the name of the todo project optional arguments: -h, --help show this help message and exit Run the init command: $ ./todo init daily Created: daily.json The final tree: $ tree -I __pycache__ . \u251c\u2500\u2500 init.py \u251c\u2500\u2500 daily.json \u2514\u2500\u2500 todo 0 directories, 3 files The next command is to implement todo remove command - I.E deleting .json file.","title":"todo init command"},{"location":"todo-app/remove-project/","text":"todo remove command Again, removing project(database) means removing our .json file. The most naive way is to create remove.py file and pass the project name as argument: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u2514\u2500\u2500 todo 1 directory, 3 files remove.py import os def remove ( project_name : str ) -> None : \"\"\" Remove the .json file with given project name Args: project_name (str): The name of the project Return: None \"\"\" os . remove ( f \" { project_name } .json\" ) print ( \"Removed: \" , project_name ) Let's get help and remove our daily project: $ ./todo -h usage: todo [-h] [-v] {init,remove} ... TODO CLI APP positional arguments: {init,remove} init Initialize the .json file with given name remove Remove the .json file with given project name optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit $ ./todo remove daily Removed: daily The final tree: $ tree -I __pycache__ . \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u2514\u2500\u2500 todo 0 directories, 3 files The next command is todo rename which should rename our project.","title":"Remove the database"},{"location":"todo-app/remove-project/#todo-remove-command","text":"Again, removing project(database) means removing our .json file. The most naive way is to create remove.py file and pass the project name as argument: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u2514\u2500\u2500 todo 1 directory, 3 files remove.py import os def remove ( project_name : str ) -> None : \"\"\" Remove the .json file with given project name Args: project_name (str): The name of the project Return: None \"\"\" os . remove ( f \" { project_name } .json\" ) print ( \"Removed: \" , project_name ) Let's get help and remove our daily project: $ ./todo -h usage: todo [-h] [-v] {init,remove} ... TODO CLI APP positional arguments: {init,remove} init Initialize the .json file with given name remove Remove the .json file with given project name optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit $ ./todo remove daily Removed: daily The final tree: $ tree -I __pycache__ . \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u2514\u2500\u2500 todo 0 directories, 3 files The next command is todo rename which should rename our project.","title":"todo remove command"},{"location":"todo-app/rename-project/","text":"todo rename command For renaming our project(database) we need old name and new name as function arguments to our rename.py . $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u2514\u2500\u2500 todo 1 directory, 4 files rename.py import os def rename ( old_name : str , new_name : str ) -> None : \"\"\" Rename the project name Args: old_name (str): old name of project new_name (str): new name of project Return: None \"\"\" os . rename ( f \" { old_name } .json\" , f \" { new_name } .json\" ) print ( f \"Renamed: { old_name } { new_name } \" ) Get the help: $ ./todo rename -h usage: todo rename [-h] old_name new_name positional arguments: old_name old name of project new_name new name of project optional arguments: -h, --help show this help message and exit Initializing: $ ./todo init daily Created: daily.json $ tree -I __pycache__ . \u251c\u2500\u2500 init.py \u251c\u2500\u2500 daily.json \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u2514\u2500\u2500 todo 0 directories, 5 files Renaming: $ ./todo rename daily DAILY Renamed: daily DAILY $ tree -I __pycache__ . \u251c\u2500\u2500 init.py \u251c\u2500\u2500 DAILY.json \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u2514\u2500\u2500 todo 0 directories, 5 files So far our TODO CLI has 3 features: $ ./todo -h usage: todo [-h] [-v] {init,remove,rename} ... TODO CLI APP positional arguments: {init,remove,rename} init Initialize the .json file with given name remove Remove the .json file with given project name rename Rename the project name optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit The next is to set up our task management commands.","title":"Rename the database"},{"location":"todo-app/rename-project/#todo-rename-command","text":"For renaming our project(database) we need old name and new name as function arguments to our rename.py . $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u2514\u2500\u2500 todo 1 directory, 4 files rename.py import os def rename ( old_name : str , new_name : str ) -> None : \"\"\" Rename the project name Args: old_name (str): old name of project new_name (str): new name of project Return: None \"\"\" os . rename ( f \" { old_name } .json\" , f \" { new_name } .json\" ) print ( f \"Renamed: { old_name } { new_name } \" ) Get the help: $ ./todo rename -h usage: todo rename [-h] old_name new_name positional arguments: old_name old name of project new_name new name of project optional arguments: -h, --help show this help message and exit Initializing: $ ./todo init daily Created: daily.json $ tree -I __pycache__ . \u251c\u2500\u2500 init.py \u251c\u2500\u2500 daily.json \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u2514\u2500\u2500 todo 0 directories, 5 files Renaming: $ ./todo rename daily DAILY Renamed: daily DAILY $ tree -I __pycache__ . \u251c\u2500\u2500 init.py \u251c\u2500\u2500 DAILY.json \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u2514\u2500\u2500 todo 0 directories, 5 files So far our TODO CLI has 3 features: $ ./todo -h usage: todo [-h] [-v] {init,remove,rename} ... TODO CLI APP positional arguments: {init,remove,rename} init Initialize the .json file with given name remove Remove the .json file with given project name rename Rename the project name optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit The next is to set up our task management commands.","title":"todo rename command"},{"location":"todo-app/task/task-add/","text":"todo task add command As task management logically is a group of commands it is better to add them in task package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u2514\u2500\u2500 __init__.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 8 files __init__.py \"\"\" Task management commands \"\"\" Get the overall help: $ ./todo -h usage: todo [-h] [-v] {init,remove,rename,task} ... TODO CLI APP positional arguments: {init,remove,rename,task} init Initialize the .json file with given name remove Remove the .json file with given project name rename Rename the project name task Task management commands optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit As you may notice the _todos package was ignored as it is considered as \"non-public\" - pure Python convention. So, the DynaCLI does not interfere any already existing code base. To implement the task adding, we need to create add.py file: tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u2514\u2500\u2500 __init__.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 9 files Here we use as a reference Implement the add CLI Command . And of course define the add function in the add.py : add.py from _todos import todo def add ( project_name : str , task : str , * tasks : str ) -> None : \"\"\" Add task to the project Args: project_name (str): the project name task (str): task name *tasks (str): variable length argument Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) for t in [ task , * tasks ]: todo_ . add ( t ) print ( \"Success\" ) Next is to add the implementations of add and add_multiple methods in Todoer class: _todos/todo.py import os from .database import DatabaseHandler from typing import NamedTuple , Any from . import DB_READ_ERROR DIR = os . path . dirname ( __file__ ) class CurrentTodo ( NamedTuple ): todo : dict [ str , list [ tuple [ str ]]] error : int class Todoer : def __init__ ( self , project_name : str ) -> None : self . project_name = project_name self . _db_handler = DatabaseHandler ( DIR + f \"/../ { project_name } .json\" ) def add ( self , task : str ) -> CurrentTodo : read = self . _db_handler . read_todos () if read . error == DB_READ_ERROR : return CurrentTodo ( read . todo_list , read . error ) read . todo_list [ self . project_name ] . append ([ \"Todo\" , task ]) write = self . _db_handler . write_todos ( read . todo_list ) return CurrentTodo ( write . todo_list , write . error ) def add_multiple ( self , tasks : tuple [ str ]) -> None : read = self . _db_handler . read_todos () for task_ in tasks : read . todo_list [ self . project_name ] . append ([ \"Todo\" , task_ ]) self . _db_handler . write_todos ( read . todo_list ) def get_todoer ( project_name : str ) -> Todoer : return Todoer ( project_name ) Now let's test our CLI: $ ./todo init daily Created: daily.json Adding 2 daily tasks: $ ./todo task add daily \"morning walk\" Success $ ./todo task add daily \"night walk\" Success Now the daily.json file looks like: {\"daily\": [[\"Todo\", \"morning walk\"], [\"Todo\", \"night walk\"]]} . How about adding multiple tasks in one shot? Adding multiple daily tasks: $ ./todo task add daily gym \"eat vegetables\" \"eat fruits\" Success If you check the daily.json : {\"daily\": [[\"Todo\", \"morning walk\"], [\"Todo\", \"night walk\"], [\"Todo\", \"gym\"], [\"Todo\", \"eat vegetables\"], [\"Todo\", \"eat fruits\"]]} If you have already noticed every task is by default marked as \"Todo\" . The next topic is to add todo task list command.","title":"Add the tasks"},{"location":"todo-app/task/task-add/#todo-task-add-command","text":"As task management logically is a group of commands it is better to add them in task package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u2514\u2500\u2500 __init__.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 8 files __init__.py \"\"\" Task management commands \"\"\" Get the overall help: $ ./todo -h usage: todo [-h] [-v] {init,remove,rename,task} ... TODO CLI APP positional arguments: {init,remove,rename,task} init Initialize the .json file with given name remove Remove the .json file with given project name rename Rename the project name task Task management commands optional arguments: -h, --help show this help message and exit -v, --version show program's version number and exit As you may notice the _todos package was ignored as it is considered as \"non-public\" - pure Python convention. So, the DynaCLI does not interfere any already existing code base. To implement the task adding, we need to create add.py file: tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u2514\u2500\u2500 __init__.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 9 files Here we use as a reference Implement the add CLI Command . And of course define the add function in the add.py : add.py from _todos import todo def add ( project_name : str , task : str , * tasks : str ) -> None : \"\"\" Add task to the project Args: project_name (str): the project name task (str): task name *tasks (str): variable length argument Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) for t in [ task , * tasks ]: todo_ . add ( t ) print ( \"Success\" ) Next is to add the implementations of add and add_multiple methods in Todoer class: _todos/todo.py import os from .database import DatabaseHandler from typing import NamedTuple , Any from . import DB_READ_ERROR DIR = os . path . dirname ( __file__ ) class CurrentTodo ( NamedTuple ): todo : dict [ str , list [ tuple [ str ]]] error : int class Todoer : def __init__ ( self , project_name : str ) -> None : self . project_name = project_name self . _db_handler = DatabaseHandler ( DIR + f \"/../ { project_name } .json\" ) def add ( self , task : str ) -> CurrentTodo : read = self . _db_handler . read_todos () if read . error == DB_READ_ERROR : return CurrentTodo ( read . todo_list , read . error ) read . todo_list [ self . project_name ] . append ([ \"Todo\" , task ]) write = self . _db_handler . write_todos ( read . todo_list ) return CurrentTodo ( write . todo_list , write . error ) def add_multiple ( self , tasks : tuple [ str ]) -> None : read = self . _db_handler . read_todos () for task_ in tasks : read . todo_list [ self . project_name ] . append ([ \"Todo\" , task_ ]) self . _db_handler . write_todos ( read . todo_list ) def get_todoer ( project_name : str ) -> Todoer : return Todoer ( project_name ) Now let's test our CLI: $ ./todo init daily Created: daily.json Adding 2 daily tasks: $ ./todo task add daily \"morning walk\" Success $ ./todo task add daily \"night walk\" Success Now the daily.json file looks like: {\"daily\": [[\"Todo\", \"morning walk\"], [\"Todo\", \"night walk\"]]} . How about adding multiple tasks in one shot? Adding multiple daily tasks: $ ./todo task add daily gym \"eat vegetables\" \"eat fruits\" Success If you check the daily.json : {\"daily\": [[\"Todo\", \"morning walk\"], [\"Todo\", \"night walk\"], [\"Todo\", \"gym\"], [\"Todo\", \"eat vegetables\"], [\"Todo\", \"eat fruits\"]]} If you have already noticed every task is by default marked as \"Todo\" . The next topic is to add todo task list command.","title":"todo task add command"},{"location":"todo-app/task/task-clear/","text":"todo task clear command How about removing all tasks? I.E clearing the project? The idea is similar to the Implement the clear CLI Command First, we need to update Todoer controller: _todos/todo.py ... class Todoer : ... def remove_all ( self ) -> CurrentTodo : \"\"\"Remove all to-dos from the database.\"\"\" write = self . _db_handler . write_todos ({ f \" { self . project_name } \" : []}) return CurrentTodo ({}, write . error ) ... The next thing is to create clear.py file in the task package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u251c\u2500\u2500 clear.py \u2502 \u251c\u2500\u2500 complete.py \u2502 \u251c\u2500\u2500 delete.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 list.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 13 files The actual implementation is similar to the original blog post, here we are intentionally using decorator as a prompt: task/clear.py from functools import wraps from _todos import todo def _prompt ( func_ : callable ) -> callable : @wraps ( func_ ) def wrapper ( project_name : str ): while True : choice = input ( \"Delete all to-dos? [y/N]:\" ) if 'y' == choice : return func_ ( project_name ) elif 'N' == choice : print ( 'Operation cancelled' ) exit ( 1 ) print ( 'Invalid choice. Try again' ) return wrapper @_prompt def clear ( project_name : str ) -> None : \"\"\" Deleting all tasks Args: project_name (str): the project name Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) todo_ . remove_all () print ( \"All to-dos were removed\" ) Get the help of the clear command: $ ./todo task clear -h usage: todo task clear [-h] project_name positional arguments: project_name the project name optional arguments: -h, --help show this help message and exit As you see, the actual code and also the DynaCLI implementation did not interfere with _prompt decorator. Let's test our clear command: $ ./todo task list daily ID. Is Done | Description 1 > morning walk 2 X night walk 3 X gym 4 X eat vegetables $ ./todo task clear daily Delete all to-dos? [y/N]:N Operation canceled ./todo task clear daily Delete all to-dos? [y/N]:sasd Invalid choice. Try again Delete all to-dos? [y/N]:y All to-dos were removed $ /todo task list daily ID. Is Done | Description Dead simple. DynaCLI just converted clear function to the CLI clear command(yes it works with decorated functions).","title":"Clear all tasks"},{"location":"todo-app/task/task-clear/#todo-task-clear-command","text":"How about removing all tasks? I.E clearing the project? The idea is similar to the Implement the clear CLI Command First, we need to update Todoer controller: _todos/todo.py ... class Todoer : ... def remove_all ( self ) -> CurrentTodo : \"\"\"Remove all to-dos from the database.\"\"\" write = self . _db_handler . write_todos ({ f \" { self . project_name } \" : []}) return CurrentTodo ({}, write . error ) ... The next thing is to create clear.py file in the task package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u251c\u2500\u2500 clear.py \u2502 \u251c\u2500\u2500 complete.py \u2502 \u251c\u2500\u2500 delete.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 list.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 13 files The actual implementation is similar to the original blog post, here we are intentionally using decorator as a prompt: task/clear.py from functools import wraps from _todos import todo def _prompt ( func_ : callable ) -> callable : @wraps ( func_ ) def wrapper ( project_name : str ): while True : choice = input ( \"Delete all to-dos? [y/N]:\" ) if 'y' == choice : return func_ ( project_name ) elif 'N' == choice : print ( 'Operation cancelled' ) exit ( 1 ) print ( 'Invalid choice. Try again' ) return wrapper @_prompt def clear ( project_name : str ) -> None : \"\"\" Deleting all tasks Args: project_name (str): the project name Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) todo_ . remove_all () print ( \"All to-dos were removed\" ) Get the help of the clear command: $ ./todo task clear -h usage: todo task clear [-h] project_name positional arguments: project_name the project name optional arguments: -h, --help show this help message and exit As you see, the actual code and also the DynaCLI implementation did not interfere with _prompt decorator. Let's test our clear command: $ ./todo task list daily ID. Is Done | Description 1 > morning walk 2 X night walk 3 X gym 4 X eat vegetables $ ./todo task clear daily Delete all to-dos? [y/N]:N Operation canceled ./todo task clear daily Delete all to-dos? [y/N]:sasd Invalid choice. Try again Delete all to-dos? [y/N]:y All to-dos were removed $ /todo task list daily ID. Is Done | Description Dead simple. DynaCLI just converted clear function to the CLI clear command(yes it works with decorated functions).","title":"todo task clear command"},{"location":"todo-app/task/task-delete/","text":"todo task delete command We should be able to delete given task from given project. Let's implement this command as well. You need to create delete.py file: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u251c\u2500\u2500 delete.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 list.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 11 files Next, we need to add delete functionality to our Todoer controller. The following code portion is from: Implement the remove CLI Command _todos/todo.py ... class Todoer : ... def delete ( self , task_id : int ) -> CurrentTodo : \"\"\"Delete a to-do from the database using its id or index.\"\"\" read = self . _db_handler . read_todos () if read . error : return CurrentTodo ({}, read . error ) try : read . todo_list [ self . project_name ] . pop ( task_id - 1 ) except IndexError : return CurrentTodo ({}, ID_ERROR ) write = self . _db_handler . write_todos ( read . todo_list ) return CurrentTodo ( write . todo_list , write . error ) ... Add the actual delete command: delete.py from _todos import todo def delete ( project_name : str , task_id : int ) -> None : \"\"\" Delete given task from the project Args: project_name (str): the project name task_id (str): the task id to be removed Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) todo_ . delete ( task_id ) print ( \"Success\" ) Let's test our delete command: $ ./todo task list daily ID. Is Done | Description 1 X morning walk 2 X night walk 3 X gym 4 X eat vegetables 5 X eat fruits Removing night walk from our daily routine(not in real life): $ ./todo task delete daily 5 Success List tasks again: $ ./todo task list daily ID. Is Done | Description 1 X morning walk 2 X night walk 3 X gym 4 X eat vegetables Again, as you have already noticed everything is dead simple and CLI depends on what you wrote in pure Python, translating arguments to CLI arguments. As a result, you don't have to write extra CLI command code - every function is already a command.","title":"Delete single task"},{"location":"todo-app/task/task-delete/#todo-task-delete-command","text":"We should be able to delete given task from given project. Let's implement this command as well. You need to create delete.py file: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u251c\u2500\u2500 delete.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 list.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 11 files Next, we need to add delete functionality to our Todoer controller. The following code portion is from: Implement the remove CLI Command _todos/todo.py ... class Todoer : ... def delete ( self , task_id : int ) -> CurrentTodo : \"\"\"Delete a to-do from the database using its id or index.\"\"\" read = self . _db_handler . read_todos () if read . error : return CurrentTodo ({}, read . error ) try : read . todo_list [ self . project_name ] . pop ( task_id - 1 ) except IndexError : return CurrentTodo ({}, ID_ERROR ) write = self . _db_handler . write_todos ( read . todo_list ) return CurrentTodo ( write . todo_list , write . error ) ... Add the actual delete command: delete.py from _todos import todo def delete ( project_name : str , task_id : int ) -> None : \"\"\" Delete given task from the project Args: project_name (str): the project name task_id (str): the task id to be removed Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) todo_ . delete ( task_id ) print ( \"Success\" ) Let's test our delete command: $ ./todo task list daily ID. Is Done | Description 1 X morning walk 2 X night walk 3 X gym 4 X eat vegetables 5 X eat fruits Removing night walk from our daily routine(not in real life): $ ./todo task delete daily 5 Success List tasks again: $ ./todo task list daily ID. Is Done | Description 1 X morning walk 2 X night walk 3 X gym 4 X eat vegetables Again, as you have already noticed everything is dead simple and CLI depends on what you wrote in pure Python, translating arguments to CLI arguments. As a result, you don't have to write extra CLI command code - every function is already a command.","title":"todo task delete command"},{"location":"todo-app/task/task-done/","text":"todo task complete command As described in original blog post: Step 6 we need to add complete command to mark the task as done by given ID. First we need to update Todoer controller: _todos/todo.py ... class Todoer : ... def set_done ( self , todo_id : int ) -> CurrentTodo : \"\"\"Set a to-do as done.\"\"\" read = self . _db_handler . read_todos () if read . error : return CurrentTodo ({}, read . error ) try : todo = read . todo_list [ self . project_name ][ todo_id - 1 ] except IndexError : return CurrentTodo ({}, ID_ERROR ) todo [ 0 ] = \"Done\" write = self . _db_handler . write_todos ( read . todo_list ) return CurrentTodo ( write . todo_list , write . error ) ... The next thing is to create complete.py file in the task package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u251c\u2500\u2500 complete.py \u2502 \u251c\u2500\u2500 delete.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 list.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 12 files Let's write our complete function: task/complete.py from _todos import todo def complete ( project_name : str , task_id : int ) -> None : \"\"\" Set to done given task. Mark as complete. Args: project_name (str): the project name task_id (str): the task id to be removed Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) todo_ . set_done ( task_id ) print ( \"Success\" ) That's it, again no need for registering your command to CLI: it is already considered as CLI command. Currently, we have 4 task commands: $ /todo task -h usage: todo task [-h] {add,complete,delete,list} ... positional arguments: {add,complete,delete,list} add Add task to the project complete Set to done given task. Mark as complete. delete Delete given task from the project list Show all tasks in given project optional arguments: -h, --help show this help message and exit Run the command: $ ./todo task list daily ID. Is Done | Description 1 X morning walk 2 X night walk 3 X gym 4 X eat vegetables $ ./todo task complete daily 1 Success $ ./todo task list daily ID. Is Done | Description 1 > morning walk 2 X night walk 3 X gym 4 X eat vegetables As you have already noticed, the status has been changed from \"X\" to \">\" marking it as a Done. In raw, daily.json file it is updated as well: {\"daily\": [[\"Done\", \"morning walk\"], [\"Todo\", \"night walk\"], [\"Todo\", \"gym\"], [\"Todo\", \"eat vegetables\"]]}","title":"Set done the task"},{"location":"todo-app/task/task-done/#todo-task-complete-command","text":"As described in original blog post: Step 6 we need to add complete command to mark the task as done by given ID. First we need to update Todoer controller: _todos/todo.py ... class Todoer : ... def set_done ( self , todo_id : int ) -> CurrentTodo : \"\"\"Set a to-do as done.\"\"\" read = self . _db_handler . read_todos () if read . error : return CurrentTodo ({}, read . error ) try : todo = read . todo_list [ self . project_name ][ todo_id - 1 ] except IndexError : return CurrentTodo ({}, ID_ERROR ) todo [ 0 ] = \"Done\" write = self . _db_handler . write_todos ( read . todo_list ) return CurrentTodo ( write . todo_list , write . error ) ... The next thing is to create complete.py file in the task package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u251c\u2500\u2500 complete.py \u2502 \u251c\u2500\u2500 delete.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 list.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 12 files Let's write our complete function: task/complete.py from _todos import todo def complete ( project_name : str , task_id : int ) -> None : \"\"\" Set to done given task. Mark as complete. Args: project_name (str): the project name task_id (str): the task id to be removed Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) todo_ . set_done ( task_id ) print ( \"Success\" ) That's it, again no need for registering your command to CLI: it is already considered as CLI command. Currently, we have 4 task commands: $ /todo task -h usage: todo task [-h] {add,complete,delete,list} ... positional arguments: {add,complete,delete,list} add Add task to the project complete Set to done given task. Mark as complete. delete Delete given task from the project list Show all tasks in given project optional arguments: -h, --help show this help message and exit Run the command: $ ./todo task list daily ID. Is Done | Description 1 X morning walk 2 X night walk 3 X gym 4 X eat vegetables $ ./todo task complete daily 1 Success $ ./todo task list daily ID. Is Done | Description 1 > morning walk 2 X night walk 3 X gym 4 X eat vegetables As you have already noticed, the status has been changed from \"X\" to \">\" marking it as a Done. In raw, daily.json file it is updated as well: {\"daily\": [[\"Done\", \"morning walk\"], [\"Todo\", \"night walk\"], [\"Todo\", \"gym\"], [\"Todo\", \"eat vegetables\"]]}","title":"todo task complete command"},{"location":"todo-app/task/task-list/","text":"todo task list command It should be easier to get back registered tasks back using CLI, rather than looking at .json files. So we are going to add simple command to list available tasks in the given project. We have changed the implementation described here: Implement the list Command Create list.py file: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 list.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 10 files Implementation: list.py import os from _todos import todo def list ( project_name : str ) -> None : \"\"\" Show all tasks in given project Args: project_name (str): the project name Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) todo_list = todo_ . get_todo_list () _format_output ( todo_list ) def _format_output ( stdout : list [ list [ str , any ]]) -> None : headers = ( \"ID. \" , \"Is Done \" , \"| Description\" ) print ( \"\" . join ( headers )) for id_ , t in enumerate ( stdout , 1 ): status = \"X\" if t [ 0 ] == 'Todo' else \">\" print ( id_ , status , t [ 1 ]) Now, we need to add get_todo_list() method to the Todoer class: _todos/todo.py ... class Todoer : ... def get_todo_list ( self ) -> list [ list [ str , Any ]]: \"\"\"Return the current to-do list.\"\"\" read = self . _db_handler . read_todos () return read . todo_list [ self . project_name ] ... Getting help and running the command: $ ./todo task list -h usage: todo task list [-h] project_name positional arguments: project_name the project name optional arguments: -h, --help show this help message and exit If you have noticed, the _format_output() function was not considered as a command - as it is a \"non-public\" function based on Python convention. Let's run the actual command: $ ./todo task list daily ID. Is Done | Description 1 X morning walk 2 X night walk 3 X gym 4 X eat vegetables 5 X eat fruits How about to add separate versions to our commands? It is possible to have different commands from various resources, and they can have different versioning. It is easy to implement it with DynaCLI, just add __version__ to the list.py file: list.py import os from _todos import todo __version__ = \"1.1\" Checking versions: $ ./todo --version todo - v1.0 $ ./todo task list --version todo task list - v1.1 So your main CLI and your commands can have different versions. The next is to add a command for deleting the task.","title":"List the tasks"},{"location":"todo-app/task/task-list/#todo-task-list-command","text":"It should be easier to get back registered tasks back using CLI, rather than looking at .json files. So we are going to add simple command to list available tasks in the given project. We have changed the implementation described here: Implement the list Command Create list.py file: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 task \u2502 \u251c\u2500\u2500 add.py \u2502 \u251c\u2500\u2500 __init__.py \u2502 \u2514\u2500\u2500 list.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 3 directories, 10 files Implementation: list.py import os from _todos import todo def list ( project_name : str ) -> None : \"\"\" Show all tasks in given project Args: project_name (str): the project name Return: None \"\"\" todo_ = todo . get_todoer ( project_name ) todo_list = todo_ . get_todo_list () _format_output ( todo_list ) def _format_output ( stdout : list [ list [ str , any ]]) -> None : headers = ( \"ID. \" , \"Is Done \" , \"| Description\" ) print ( \"\" . join ( headers )) for id_ , t in enumerate ( stdout , 1 ): status = \"X\" if t [ 0 ] == 'Todo' else \">\" print ( id_ , status , t [ 1 ]) Now, we need to add get_todo_list() method to the Todoer class: _todos/todo.py ... class Todoer : ... def get_todo_list ( self ) -> list [ list [ str , Any ]]: \"\"\"Return the current to-do list.\"\"\" read = self . _db_handler . read_todos () return read . todo_list [ self . project_name ] ... Getting help and running the command: $ ./todo task list -h usage: todo task list [-h] project_name positional arguments: project_name the project name optional arguments: -h, --help show this help message and exit If you have noticed, the _format_output() function was not considered as a command - as it is a \"non-public\" function based on Python convention. Let's run the actual command: $ ./todo task list daily ID. Is Done | Description 1 X morning walk 2 X night walk 3 X gym 4 X eat vegetables 5 X eat fruits How about to add separate versions to our commands? It is possible to have different commands from various resources, and they can have different versioning. It is easy to implement it with DynaCLI, just add __version__ to the list.py file: list.py import os from _todos import todo __version__ = \"1.1\" Checking versions: $ ./todo --version todo - v1.0 $ ./todo task list --version todo task list - v1.1 So your main CLI and your commands can have different versions. The next is to add a command for deleting the task.","title":"todo task list command"},{"location":"todo-app/task/todo-app-database-handler/","text":"Setup the database operations Here we grab Step 2 and Step 4 from the original article and mostly ignored other code portions. As we have several helper code we can store them in the _todos package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u2514\u2500\u2500 __init__.py 2 directories, 6 files Let's add some preliminary constants: __init__.py ( SUCCESS , DIR_ERROR , FILE_ERROR , DB_READ_ERROR , DB_WRITE_ERROR , JSON_ERROR , ID_ERROR , ) = range ( 7 ) ERRORS = { DIR_ERROR : \"config directory error\" , FILE_ERROR : \"config file error\" , DB_READ_ERROR : \"database read error\" , DB_WRITE_ERROR : \"database write error\" , ID_ERROR : \"to-do id error\" , } As you may notice we have removed redundant app name and version information from the __init__.py which was described in Step 2 . Let's add our database handler class: database.py import json from typing import NamedTuple , Any from . import JSON_ERROR , SUCCESS , DB_READ_ERROR , DB_WRITE_ERROR class DBResponse ( NamedTuple ): todo_list : dict [ str , list [ list [ str , Any ]]] error : int class DatabaseHandler : def __init__ ( self , db_path : str ) -> None : self . _db_path = db_path def read_todos ( self ) -> DBResponse : try : with open ( self . _db_path , \"r\" ) as db : try : return DBResponse ( json . loads ( db . readline ()), SUCCESS ) except json . JSONDecodeError : # Catch wrong JSON format return DBResponse ({}, JSON_ERROR ) except OSError : # Catch file IO problems return DBResponse ({}, DB_READ_ERROR ) def write_todos ( self , todo_list : dict [ str , list [ list [ str , Any ]]]) -> DBResponse : try : with open ( self . _db_path , \"w\" ) as db : json . dump ( todo_list , db ) return DBResponse ( todo_list , SUCCESS ) except OSError : # Catch file IO problems return DBResponse ( todo_list , DB_WRITE_ERROR ) Again, we have slightly changed the code but most of it is from Step 4 . We added extra package to our CLI path, it should be broken right now? Of course not. In pure Python convention the names which are started with _ (underscore) are considered as \"non-public\". DynaCLI follows this convention, and we just ignore \"non-public\" packages - they are not considered as part of CLI. The next is to add a Controller class for our TODOs.","title":"Setup TODO app database handler"},{"location":"todo-app/task/todo-app-database-handler/#setup-the-database-operations","text":"Here we grab Step 2 and Step 4 from the original article and mostly ignored other code portions. As we have several helper code we can store them in the _todos package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u2514\u2500\u2500 __init__.py 2 directories, 6 files Let's add some preliminary constants: __init__.py ( SUCCESS , DIR_ERROR , FILE_ERROR , DB_READ_ERROR , DB_WRITE_ERROR , JSON_ERROR , ID_ERROR , ) = range ( 7 ) ERRORS = { DIR_ERROR : \"config directory error\" , FILE_ERROR : \"config file error\" , DB_READ_ERROR : \"database read error\" , DB_WRITE_ERROR : \"database write error\" , ID_ERROR : \"to-do id error\" , } As you may notice we have removed redundant app name and version information from the __init__.py which was described in Step 2 . Let's add our database handler class: database.py import json from typing import NamedTuple , Any from . import JSON_ERROR , SUCCESS , DB_READ_ERROR , DB_WRITE_ERROR class DBResponse ( NamedTuple ): todo_list : dict [ str , list [ list [ str , Any ]]] error : int class DatabaseHandler : def __init__ ( self , db_path : str ) -> None : self . _db_path = db_path def read_todos ( self ) -> DBResponse : try : with open ( self . _db_path , \"r\" ) as db : try : return DBResponse ( json . loads ( db . readline ()), SUCCESS ) except json . JSONDecodeError : # Catch wrong JSON format return DBResponse ({}, JSON_ERROR ) except OSError : # Catch file IO problems return DBResponse ({}, DB_READ_ERROR ) def write_todos ( self , todo_list : dict [ str , list [ list [ str , Any ]]]) -> DBResponse : try : with open ( self . _db_path , \"w\" ) as db : json . dump ( todo_list , db ) return DBResponse ( todo_list , SUCCESS ) except OSError : # Catch file IO problems return DBResponse ( todo_list , DB_WRITE_ERROR ) Again, we have slightly changed the code but most of it is from Step 4 . We added extra package to our CLI path, it should be broken right now? Of course not. In pure Python convention the names which are started with _ (underscore) are considered as \"non-public\". DynaCLI follows this convention, and we just ignore \"non-public\" packages - they are not considered as part of CLI. The next is to add a Controller class for our TODOs.","title":"Setup the database operations"},{"location":"todo-app/task/todo-controller-class/","text":"Setup todo controller class This section is primarily adopted from Step 4 and Step 5 Again we have omitted redundant parts and keep only needed code portions. Let's create todo.py file in our _todos package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 2 directories, 7 files And add our controller class: todo.py import os from .database import DatabaseHandler from typing import NamedTuple , Any from . import DB_READ_ERROR , ID_ERROR DIR = os . path . dirname ( __file__ ) class CurrentTodo ( NamedTuple ): todo : dict [ str , list [ list [ str , Any ]]] error : int class Todoer : def __init__ ( self , project_name : str ) -> None : self . project_name = project_name self . _db_handler = DatabaseHandler ( DIR + f \"/../ { project_name } .json\" ) def get_todoer ( project_name : str ) -> Todoer : return Todoer ( project_name ) We have added get_todoer function to get back the Todoer object - it will be used in the actual CLI commands. The next is to implement the task adding CLI command.","title":"Setup TODO app todo controller class"},{"location":"todo-app/task/todo-controller-class/#setup-todo-controller-class","text":"This section is primarily adopted from Step 4 and Step 5 Again we have omitted redundant parts and keep only needed code portions. Let's create todo.py file in our _todos package: $ tree . \u2514\u2500\u2500 TODO \u251c\u2500\u2500 init.py \u251c\u2500\u2500 remove.py \u251c\u2500\u2500 rename.py \u251c\u2500\u2500 todo \u2514\u2500\u2500 _todos \u251c\u2500\u2500 database.py \u251c\u2500\u2500 __init__.py \u2514\u2500\u2500 todo.py 2 directories, 7 files And add our controller class: todo.py import os from .database import DatabaseHandler from typing import NamedTuple , Any from . import DB_READ_ERROR , ID_ERROR DIR = os . path . dirname ( __file__ ) class CurrentTodo ( NamedTuple ): todo : dict [ str , list [ list [ str , Any ]]] error : int class Todoer : def __init__ ( self , project_name : str ) -> None : self . project_name = project_name self . _db_handler = DatabaseHandler ( DIR + f \"/../ { project_name } .json\" ) def get_todoer ( project_name : str ) -> Todoer : return Todoer ( project_name ) We have added get_todoer function to get back the Todoer object - it will be used in the actual CLI commands. The next is to implement the task adding CLI command.","title":"Setup todo controller class"}]}